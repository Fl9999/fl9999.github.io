<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.2.0">

  <link rel="apple-touch-icon" sizes="180x180" href="../images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="../images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="../images/favicon-16x16-next.png">
  <link rel="mask-icon" href="../images/logo.svg" color="#222">

<link rel="stylesheet" href="../css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"csms.tech","root":"/","images":"../images","scheme":"Gemini","darkmode":true,"version":"8.14.2","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":true,"nav":null,"activeClass":"gitalk"},"stickytabs":false,"motion":{"enable":true,"async":true,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeIn","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"../search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="../js/config.js"></script>

    <meta name="description" content="版本信息 Centos 7 Kubernetes 1.24 Prometheus 2.44.0 AlertManager 0.24.0  Prometheus 部署步骤为 Prometheus 创建专用的 Namespace，此处创建 prometheuskubectl create namespace prometheus  创建集群角色Prometheus 使用 Kubernetes API">
<meta property="og:type" content="article">
<meta property="og:title" content="K8S 上安装 Prometheus 并监控 K8S 集群">
<meta property="og:url" content="http://csms.tech/202212141608/index.html">
<meta property="og:site_name" content="L B T">
<meta property="og:description" content="版本信息 Centos 7 Kubernetes 1.24 Prometheus 2.44.0 AlertManager 0.24.0  Prometheus 部署步骤为 Prometheus 创建专用的 Namespace，此处创建 prometheuskubectl create namespace prometheus  创建集群角色Prometheus 使用 Kubernetes API">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.csms.tech/img_109.png">
<meta property="og:image" content="https://i.csms.tech/img_155.png">
<meta property="og:image" content="https://i.csms.tech/img_156.png">
<meta property="og:image" content="https://i.csms.tech/img_157.png">
<meta property="og:image" content="https://i.csms.tech/img_158.png">
<meta property="og:image" content="https://i.csms.tech/img_159.png">
<meta property="og:image" content="https://i.csms.tech/img_222.png">
<meta property="og:image" content="https://i.csms.tech/img_177.png">
<meta property="og:image" content="https://i.csms.tech/img_152.png">
<meta property="og:image" content="https://i.csms.tech/img_176.png">
<meta property="article:published_time" content="2022-12-14T08:09:03.000Z">
<meta property="article:modified_time" content="2023-10-04T03:01:32.000Z">
<meta property="article:author" content="COSMOS">
<meta property="article:tag" content="Prometheus">
<meta property="article:tag" content="Kubernetes">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.csms.tech/img_109.png">


<link rel="canonical" href="http://csms.tech/202212141608/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://csms.tech/202212141608/","path":"202212141608/","title":"K8S 上安装 Prometheus 并监控 K8S 集群"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>K8S 上安装 Prometheus 并监控 K8S 集群 | L B T</title>
  








  <noscript>
    <link rel="stylesheet" href="../css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">L B T</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">记 录 过 去 的 经 验</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="../index.html" rel="section"><i class="fa fa-earth-americas fa-fw"></i>首页</a></li><li class="menu-item menu-item-categories"><a href="../categories/" rel="section"><i class="fa fa-folder-tree fa-fw"></i>总目录<span class="badge">51</span></a></li><li class="menu-item menu-item-linux"><a href="../categories/Linux" rel="section"><i class="fa fa-brands fa-linux fa-fw"></i>Linux</a></li><li class="menu-item menu-item-python"><a href="../categories/Python" rel="section"><i class="fa fa-brands fa-python fa-fw"></i>Python</a></li><li class="menu-item menu-item-docker"><a href="../categories/Docker" rel="section"><i class="fa fa-brands fa-docker fa-fw"></i>Docker</a></li><li class="menu-item menu-item-kubernetes"><a href="../categories/Kubernetes" rel="section"><i class="fa fa-dharmachakra fa-fw"></i>Kubernetes</a></li><li class="menu-item menu-item-tags"><a href="../tags/" rel="section"><i class="fa fa-tornado fa-fw"></i>标签<span class="badge">78</span></a></li><li class="menu-item menu-item-archives"><a href="../archives/" rel="section"><i class="fa fa-rectangle-list fa-fw"></i>列表<span class="badge">250</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章总目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%89%88%E6%9C%AC%E4%BF%A1%E6%81%AF"><span class="nav-number">1.</span> <span class="nav-text">版本信息</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Prometheus-%E9%83%A8%E7%BD%B2%E6%AD%A5%E9%AA%A4"><span class="nav-number">2.</span> <span class="nav-text">Prometheus 部署步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA-Prometheus-%E5%88%9B%E5%BB%BA%E4%B8%93%E7%94%A8%E7%9A%84-Namespace%EF%BC%8C%E6%AD%A4%E5%A4%84%E5%88%9B%E5%BB%BA-prometheus"><span class="nav-number">2.1.</span> <span class="nav-text">为 Prometheus 创建专用的 Namespace，此处创建 prometheus</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E9%9B%86%E7%BE%A4%E8%A7%92%E8%89%B2"><span class="nav-number">2.2.</span> <span class="nav-text">创建集群角色</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA-ConfigMap-%E4%BB%A5%E5%A4%96%E9%83%A8%E5%8C%96-Prometheus-%E9%85%8D%E7%BD%AE"><span class="nav-number">2.3.</span> <span class="nav-text">创建 ConfigMap 以外部化 Prometheus 配置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2-Prometheus-Server"><span class="nav-number">2.4.</span> <span class="nav-text">部署 Prometheus Server</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2-Grafana"><span class="nav-number">2.5.</span> <span class="nav-text">部署 Grafana</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9%E4%B8%8A%E9%83%A8%E7%BD%B2-node-exporter-%E5%AF%B9%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9%E8%BF%9B%E8%A1%8C%E7%9B%91%E6%8E%A7"><span class="nav-number">2.6.</span> <span class="nav-text">集群节点上部署 node-exporter 对集群节点进行监控</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE-Prometheus-%E6%94%AF%E6%8C%81-Kubernetes-%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0"><span class="nav-number">2.7.</span> <span class="nav-text">配置 Prometheus 支持 Kubernetes 服务发现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE-Prometheus-%E6%94%AF%E6%8C%81-Kubernetes-%E8%8A%82%E7%82%B9%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0%E5%B9%B6%E6%8A%93%E5%8F%96%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87"><span class="nav-number">2.7.1.</span> <span class="nav-text">配置 Prometheus 支持 Kubernetes 节点自动发现并抓取监控指标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE-Prometheus-%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0-kube-apiserver-%E5%B9%B6%E8%AF%BB%E5%8F%96%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87"><span class="nav-number">2.7.2.</span> <span class="nav-text">配置 Prometheus 自动发现 kube-apiserver 并读取监控指标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE-Prometheus-%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0-kubelet-%E5%B9%B6%E8%AF%BB%E5%8F%96%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87"><span class="nav-number">2.7.3.</span> <span class="nav-text">配置 Prometheus 自动发现 kubelet 并读取监控指标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE-Prometheus-%E4%BB%8E-cAdvisor-%E8%AF%BB%E5%8F%96%E7%9B%91%E6%8E%A7%E6%95%B0%E6%8D%AE"><span class="nav-number">2.7.4.</span> <span class="nav-text">配置 Prometheus 从 cAdvisor 读取监控数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE-Prometheus-%E6%8A%93%E5%8F%96-Kubernetes-%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%8A%B6%E6%80%81%E6%8C%87%E6%A0%87"><span class="nav-number">2.7.5.</span> <span class="nav-text">配置 Prometheus 抓取 Kubernetes 集群资源状态指标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#etcd-%E7%BB%84%E4%BB%B6%E7%9B%91%E6%8E%A7"><span class="nav-number">2.7.6.</span> <span class="nav-text">etcd 组件监控</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Scheduler-%E7%BB%84%E4%BB%B6%E7%9B%91%E6%8E%A7"><span class="nav-number">2.7.7.</span> <span class="nav-text">Scheduler 组件监控</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Controller-Manager-%E7%BB%84%E4%BB%B6%E7%9B%91%E6%8E%A7"><span class="nav-number">2.7.8.</span> <span class="nav-text">Controller Manager 组件监控</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-proxy-%E7%BB%84%E4%BB%B6%E7%9B%91%E6%8E%A7"><span class="nav-number">2.7.9.</span> <span class="nav-text">kube-proxy 组件监控</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CoreDNS-%E7%BB%84%E4%BB%B6%E7%9B%91%E6%8E%A7"><span class="nav-number">2.7.10.</span> <span class="nav-text">CoreDNS 组件监控</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE-Prometheus-%E6%8A%93%E5%8F%96-Ingress-Nginx-%E6%8C%87%E6%A0%87"><span class="nav-number">2.7.11.</span> <span class="nav-text">配置 Prometheus 抓取 Ingress-Nginx 指标</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF"><span class="nav-number">3.</span> <span class="nav-text">常见错误</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#failed-to-list-v1-Pod-pods-is-forbidden-User-quot-system-serviceaccount-prometheus-default-quot-cannot-list-resource-quot-pods-quot-in-API-group-quot-quot-at-the-cluster-scope%E2%80%9D"><span class="nav-number">3.1.</span> <span class="nav-text">failed to list *v1.Pod: pods is forbidden: User &quot;system:serviceaccount:prometheus:default&quot; cannot list resource &quot;pods&quot; in API group &quot;&quot; at the cluster scope”</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#server-returned-HTTP-status-400-Bad-Request"><span class="nav-number">3.2.</span> <span class="nav-text">server returned HTTP status 400 Bad Request</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#opening-storage-failed-lock-DB-directory-resource-temporarily-unavailable"><span class="nav-number">3.3.</span> <span class="nav-text">opening storage failed: lock DB directory: resource temporarily unavailable</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cAdvisor-%E8%8E%B7%E5%8F%96-Pod-%E6%8C%87%E6%A0%87%E5%85%83%E6%95%B0%E6%8D%AE%E5%BC%82%E5%B8%B8"><span class="nav-number">3.4.</span> <span class="nav-text">cAdvisor 获取 Pod 指标元数据异常</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E4%BF%A1%E6%81%AF"><span class="nav-number">3.4.1.</span> <span class="nav-text">环境信息</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E6%A1%A3"><span class="nav-number">4.</span> <span class="nav-text">参考文档</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%84%9A%E6%B3%A8"><span class="nav-number">5.</span> <span class="nav-text">脚注</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">COSMOS</p>
  <div class="site-description" itemprop="description">得 能 莫 忘</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="../archives/">
          <span class="site-state-item-count">250</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="../categories/">
        <span class="site-state-item-count">51</span>
        <span class="site-state-item-name">目录</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="../tags/">
        <span class="site-state-item-count">78</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://csms.tech/202212141608/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="../images/avatar.gif">
      <meta itemprop="name" content="COSMOS">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="L B T">
      <meta itemprop="description" content="得 能 莫 忘">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="K8S 上安装 Prometheus 并监控 K8S 集群 | L B T">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          K8S 上安装 Prometheus 并监控 K8S 集群
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-12-14 16:09:03" itemprop="dateCreated datePublished" datetime="2022-12-14T16:09:03+08:00">2022-12-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-10-04 11:01:32" itemprop="dateModified" datetime="2023-10-04T11:01:32+08:00">2023-10-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">上层目录</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="../categories/Tools/" itemprop="url" rel="index"><span itemprop="name">Tools</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="../categories/Tools/Prometheus/" itemprop="url" rel="index"><span itemprop="name">Prometheus</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="版本信息"><a href="#版本信息" class="headerlink" title="版本信息"></a>版本信息</h1><ul>
<li>Centos 7</li>
<li>Kubernetes 1.24</li>
<li>Prometheus 2.44.0</li>
<li>AlertManager 0.24.0</li>
</ul>
<h1 id="Prometheus-部署步骤"><a href="#Prometheus-部署步骤" class="headerlink" title="Prometheus 部署步骤"></a>Prometheus 部署步骤</h1><h2 id="为-Prometheus-创建专用的-Namespace，此处创建-prometheus"><a href="#为-Prometheus-创建专用的-Namespace，此处创建-prometheus" class="headerlink" title="为 Prometheus 创建专用的 Namespace，此处创建 prometheus"></a>为 Prometheus 创建专用的 Namespace，此处创建 <code>prometheus</code></h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl create namespace prometheus</span><br></pre></td></tr></table></figure>

<h2 id="创建集群角色"><a href="#创建集群角色" class="headerlink" title="创建集群角色"></a>创建集群角色</h2><p>Prometheus 使用 Kubernetes API 从 Nodes、Pods、Deployments 等等中读取所有可用的指标。因此，我们需要创建一个包含读取所需 API 组的 RBAC 策略，并将该策略绑定到新建的 <code>prometheus</code> 命名空间。<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="[如何部署 Prometheus 监控K8S](https://zhuanlan.zhihu.com/p/456205833)">[1]</span></a></sup></p>
<ol>
<li>创建一个名为 <code>prometheusClusterRole.yaml</code>的文件，并复制以下 RBAC 角色。<blockquote>
<p>在下面给出的角色中，可以看到，我们已经往 <code>nodes</code>, <code>services endpoints</code>, <code>pods</code> 和 <code>ingresses</code> 中添加了 <code>get</code>，<code>list</code> 以及 <code>watch</code> 权限。角色绑定被绑定到监控命名空间。如果有任何要从其他对象中检索指标的用例，则需要将其添加到此集群角色中。</p>
</blockquote>
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&quot;&quot;]</span><br><span class="line">  resources:</span><br><span class="line">  - nodes</span><br><span class="line">  - nodes/proxy</span><br><span class="line">  - nodes/metrics</span><br><span class="line">  - services</span><br><span class="line">  - endpoints</span><br><span class="line">  - pods</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">- apiGroups:</span><br><span class="line">  - extensions</span><br><span class="line">  resources:</span><br><span class="line">  - ingresses</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">- nonResourceURLs: [&quot;/metrics&quot;]</span><br><span class="line">  verbs: [&quot;get&quot;]</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: prometheus</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: default</span><br><span class="line">  namespace: prometheus</span><br></pre></td></tr></table></figure></li>
<li>使用下面的命令创建角色<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply -f prometheusClusterRole.yaml</span><br></pre></td></tr></table></figure></li>
</ol>
<span id="more"></span>
<h2 id="创建-ConfigMap-以外部化-Prometheus-配置"><a href="#创建-ConfigMap-以外部化-Prometheus-配置" class="headerlink" title="创建 ConfigMap 以外部化 Prometheus 配置"></a>创建 ConfigMap 以外部化 Prometheus 配置</h2><p>Prometheus 的所有配置都是 <code>prometheus.yaml</code> 文件的一部分，而 <code>Alertmanager</code> 的所有警报规则都配置在 <code>prometheus.rules</code></p>
<ul>
<li><code>prometheus.yaml</code> - 这是主要的 Prometheus 配置，包含所有抓取配置、服务发现详细信息、存储位置、数据保留配置等</li>
<li><code>*.rules</code> - 此文件包含所有 Prometheus 警报规则</li>
</ul>
<p>通过将 Prometheus 配置外部化到 Kubernetes 的 <code>ConfigMap</code>，那么就无需当需要添加或删除配置时，再来构建 Prometheus 镜像。这里需要更新配置映射并重新启动 Prometheus Pod 以应用新配置。</p>
<p>使用以下内容创建 <code>ConfigMap</code>。开始学习时可以先使用 <a href="/202211221610/" title="基础配置">基础配置</a>，熟悉之后逐步添加配置。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus-server-conf</span><br><span class="line">  labels:</span><br><span class="line">    name: prometheus-server-conf</span><br><span class="line">  namespace: prometheus</span><br><span class="line">data:</span><br><span class="line">  prometheus.rules: |-</span><br><span class="line">    groups:</span><br><span class="line">    - name: devopscube demo alert</span><br><span class="line">      rules:</span><br><span class="line">      - alert: High Pod Memory</span><br><span class="line">        expr: sum(container_memory_usage_bytes) &gt; 1</span><br><span class="line">        for: 1m</span><br><span class="line">        labels:</span><br><span class="line">          severity: slack</span><br><span class="line">        annotations:</span><br><span class="line">          summary: High Memory Usage</span><br><span class="line">          </span><br><span class="line">  prometheus.yml: |-</span><br><span class="line">    global:</span><br><span class="line">      scrape_interval: 5s</span><br><span class="line">      evaluation_interval: 5s</span><br><span class="line">    </span><br><span class="line">    alerting:</span><br><span class="line">      alertmanagers:</span><br><span class="line">        - static_configs:</span><br><span class="line">            - targets: [&#x27;localhost:9093&#x27;]</span><br><span class="line">    </span><br><span class="line">    rule_files:</span><br><span class="line">      - /etc/prometheus/*.rules</span><br><span class="line">    </span><br><span class="line">    scrape_configs:</span><br><span class="line">      - job_name: &#x27;prometheus&#x27;</span><br><span class="line">        static_configs:</span><br><span class="line">        - targets: [&#x27;localhost:9090&#x27;]</span><br><span class="line">        </span><br><span class="line">      - job_name: &#x27;kubernetes-nodes&#x27;</span><br><span class="line">        tls_config:</span><br><span class="line">          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">        kubernetes_sd_configs:</span><br><span class="line">        - role: node</span><br><span class="line">        relabel_configs:</span><br><span class="line">        - source_labels: [__address__]</span><br><span class="line">          regex: &#x27;(.*):10250&#x27;</span><br><span class="line">          replacement: &#x27;$&#123;1&#125;:9100&#x27;</span><br><span class="line">          target_label: __address__</span><br><span class="line">          action: replace</span><br><span class="line">        - action: labelmap</span><br><span class="line">          regex: __meta_kubernetes_node_label_(.+)</span><br><span class="line">    </span><br><span class="line">      - job_name: &#x27;kubernetes-kubelet&#x27;</span><br><span class="line">        kubernetes_sd_configs:</span><br><span class="line">        - role: node</span><br><span class="line">        scheme: https</span><br><span class="line">        tls_config:</span><br><span class="line">          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">          insecure_skip_verify: true</span><br><span class="line">        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">        relabel_configs:</span><br><span class="line">        - action: labelmap</span><br><span class="line">          regex: __meta_kubernetes_node_label_(.+)</span><br><span class="line">      - job_name: &#x27;kubernetes-cadvisor&#x27;</span><br><span class="line">        scheme: https</span><br><span class="line">        tls_config:</span><br><span class="line">          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">          insecure_skip_verify: true</span><br><span class="line">        kubernetes_sd_configs:</span><br><span class="line">        - role: node</span><br><span class="line">        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">        relabel_configs:</span><br><span class="line">        - source_labels: [__meta_kubernetes_node_name]</span><br><span class="line">          regex: (.+)</span><br><span class="line">          target_label: __metrics_path__</span><br><span class="line">          replacement: metrics/cadvisor</span><br><span class="line">        - action: labelmap</span><br><span class="line">          regex: __meta_kubernetes_node_label_(.+)</span><br><span class="line">      </span><br></pre></td></tr></table></figure>

<p><code>prometheus.yaml</code> 包含了用以发现动态运行在 Kubernetes 集群中的资源的配置。</p>
<h2 id="部署-Prometheus-Server"><a href="#部署-Prometheus-Server" class="headerlink" title="部署 Prometheus Server"></a>部署 Prometheus Server</h2><p>使用以下内容创建 Deployment，在此配置中，我们将 Prometheus 的 <code>ConfigMap</code> 作为文件安装在 <code>/etc/prometheus</code> 中，持久化存储使用 PV。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus-pod</span><br><span class="line">  namespace: prometheus</span><br><span class="line">  labels:</span><br><span class="line">    app: prometheus-server</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: prometheus-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: prometheus-server</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: prometheus</span><br><span class="line">          image: prom/prometheus</span><br><span class="line">          args:</span><br><span class="line">            - &quot;--storage.tsdb.retention.time=12h&quot;</span><br><span class="line">            - &quot;--config.file=/etc/prometheus/prometheus.yml&quot;</span><br><span class="line">            - &quot;--storage.tsdb.path=/prometheus/&quot;</span><br><span class="line">            - --web.enable-lifecycle</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 9090</span><br><span class="line">          resources:</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 500m</span><br><span class="line">              memory: 500M</span><br><span class="line">            limits:</span><br><span class="line">              cpu: 1</span><br><span class="line">              memory: 1Gi</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: prometheus-config-volume</span><br><span class="line">              mountPath: /etc/prometheus/</span><br><span class="line">            - name: prometheus-storage-volume</span><br><span class="line">              mountPath: /prometheus/</span><br><span class="line">      volumes:</span><br><span class="line">        - name: prometheus-config-volume</span><br><span class="line">          configMap:</span><br><span class="line">            defaultMode: 420</span><br><span class="line">            name: prometheus-server-conf</span><br><span class="line">  </span><br><span class="line">        - name: prometheus-storage-volume</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: prometheus-pvc</span><br></pre></td></tr></table></figure>

<p>使用以下内容为 Prometheus Server 创建 Ingress</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus-service</span><br><span class="line">  namespace: prometheus</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - name: prometheus-port</span><br><span class="line">      port: 8090</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 9090</span><br><span class="line">  selector:</span><br><span class="line">    app: prometheus-server</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus-ui</span><br><span class="line">  namespace: prometheus</span><br><span class="line"></span><br><span class="line">spec:</span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules:</span><br><span class="line">  - host: prometheus.example.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - backend:</span><br><span class="line">          service:</span><br><span class="line">            name: prometheus-service</span><br><span class="line">            port: </span><br><span class="line">              number: 8090</span><br><span class="line">        path: /</span><br><span class="line">        pathType: Prefix</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>部署完成后，使用 <code>prometheus.example.com</code> 访问<br><img src="https://i.csms.tech/img_109.png"><br>可以通过 url <code>http://prometheus.example.com/config</code> 查看当前的 prometheus 配置</p>
<h2 id="部署-Grafana"><a href="#部署-Grafana" class="headerlink" title="部署 Grafana"></a>部署 Grafana</h2><p>如需部署 Grafana，可以使用以下配置，需要持久化数据目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus-pod</span><br><span class="line">  namespace: prometheus</span><br><span class="line">  labels:</span><br><span class="line">    app: prometheus-server</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: prometheus-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: prometheus-server</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: prometheus</span><br><span class="line">          image: prom/prometheus</span><br><span class="line">          args:</span><br><span class="line">            - &quot;--storage.tsdb.retention.time=12h&quot;</span><br><span class="line">            - &quot;--config.file=/etc/prometheus/prometheus.yml&quot;</span><br><span class="line">            - &quot;--storage.tsdb.path=/prometheus/&quot;</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 9090</span><br><span class="line">          resources:</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 500m</span><br><span class="line">              memory: 500M</span><br><span class="line">            limits:</span><br><span class="line">              cpu: 1</span><br><span class="line">              memory: 1Gi</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: prometheus-config-volume</span><br><span class="line">              mountPath: /etc/prometheus/</span><br><span class="line">            - name: prometheus-storage-volume</span><br><span class="line">              mountPath: /prometheus/</span><br><span class="line">              subPath: prometheus</span><br><span class="line">        - name: grafana</span><br><span class="line">          image: grafana/grafana</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 3000</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: prometheus-storage-volume</span><br><span class="line">              mountPath: /var/lib/grafana</span><br><span class="line">              subPath: grafana</span><br><span class="line">      volumes:</span><br><span class="line">        - name: prometheus-config-volume</span><br><span class="line">          configMap:</span><br><span class="line">            defaultMode: 420</span><br><span class="line">            name: prometheus-server-conf</span><br><span class="line">  </span><br><span class="line">        - name: prometheus-storage-volume</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: prometheus-pvc</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus-service</span><br><span class="line">  namespace: prometheus</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - name: prometheus-port</span><br><span class="line">      port: 8090</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 9090</span><br><span class="line">    - name: grafana-port</span><br><span class="line">      port: 3000</span><br><span class="line">      targetPort: 3000</span><br><span class="line">  selector:</span><br><span class="line">    app: prometheus-server</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus-ui</span><br><span class="line">  namespace: prometheus</span><br><span class="line"></span><br><span class="line">spec:</span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules:</span><br><span class="line">  - host: prometheus.example.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - backend:</span><br><span class="line">          service:</span><br><span class="line">            name: prometheus-service</span><br><span class="line">            port: </span><br><span class="line">              number: 8090</span><br><span class="line">        path: /</span><br><span class="line">        pathType: Prefix</span><br><span class="line">  - host: grafana.example.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - backend:</span><br><span class="line">          service:</span><br><span class="line">            name: prometheus-service</span><br><span class="line">            port:</span><br><span class="line">              number: 3000</span><br><span class="line">        path: /</span><br><span class="line">        pathType: Prefix</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="集群节点上部署-node-exporter-对集群节点进行监控"><a href="#集群节点上部署-node-exporter-对集群节点进行监控" class="headerlink" title="集群节点上部署 node-exporter 对集群节点进行监控"></a>集群节点上部署 node-exporter 对集群节点进行监控</h2><p>使用 <code>DaemonSet</code> 方式在每个 Node 上部署 <code>node-exporter</code>，本示例运行在 <code>prometheus</code> 的 Namespace 中。为了暴露 <code>node-exporter</code> 给 Prometheus Server ，可以使用以下方法。建议使用第 2 种方法。</p>
<ol>
<li><p>Service 的 port type 配置为 <code>NodePort</code>。<a href="https://csms.tech/202209121102/#修改-Service-可使用的-nodePort-端口范围">配置 Kubernetes API Server 允许 9100 端口配置为 NodePort 参考</a>，如此可以直接通过节点 IP 访问 <code>node-exporter</code></p>
<p>为了确保 Prometheus Server 请求查询指定节点的监控数据的流量都能被本节点上的 <code>node-exporter</code> 处理，建议配置 <code>externalTrafficPolicy: Local</code>、<code>internalTrafficPolicy: Local</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: node-exporter</span><br><span class="line">  namespace: prometheus</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: node-exporter</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      name: node-exporter</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: node-exporter</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: node-exporter</span><br><span class="line">        image: prom/node-exporter</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9100</span><br><span class="line">          protocol: TCP</span><br><span class="line">          name: http</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: node-exporter</span><br><span class="line">  name: node-exporter</span><br><span class="line">  namespace: prometheus</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 9100</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 9100</span><br><span class="line">    nodePort: 39100</span><br><span class="line">  selector:</span><br><span class="line">    name: node-exporter</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  type: NodePort</span><br><span class="line">  externalTrafficPolicy: Local</span><br><span class="line">  internalTrafficPolicy: Local</span><br></pre></td></tr></table></figure></li>
<li><p>不使用 Service，直接配置 Pod 网络为 <code>hostNetwork</code>，如此 Pod 的 Network Namespace 是在节点的 Root Network Namespace，可以直接使用节点的网络资源。同时配置 Pod 使用节点的 PID、IPC 资源。挂载主机的 <code>/dev</code>、<code>/proc</code>、<code>/sys</code> 等目录到容器中，以使 <code>node-exporter</code> 可以监控到节点上的数据。<strong>否则，node-expoter 因为权限问题无法监控到节点的资源</strong></p>
 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: node-exporter</span><br><span class="line">  namespace: prometheus</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: node-exporter</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      name: node-exporter</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: node-exporter</span><br><span class="line">    spec:</span><br><span class="line">      hostPid: true</span><br><span class="line">      hostIPC: true</span><br><span class="line">      hostNetwork: true</span><br><span class="line">      </span><br><span class="line">      </span><br><span class="line">      containers:</span><br><span class="line">      - name: node-exporter</span><br><span class="line">        image: prom/node-exporter</span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: true</span><br><span class="line">        args:</span><br><span class="line">          - --path.procfs</span><br><span class="line">          - /host/proc</span><br><span class="line">          - --path.sysfs</span><br><span class="line">          - /host/sys</span><br><span class="line">          - --collector.filesystem.ignored-mount-points</span><br><span class="line">          - &#x27;&quot;^/(sys|proc|dev|host|etc)($|/)&quot;&#x27;</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: dev</span><br><span class="line">          mountPath: /host/dev</span><br><span class="line">        - name: proc</span><br><span class="line">          mountPath: /host/proc</span><br><span class="line">        - name: sys</span><br><span class="line">          mountPath: /host/sys</span><br><span class="line">        - name: rootfs</span><br><span class="line">          mountPath: /rootfs</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9100</span><br><span class="line">          protocol: TCP</span><br><span class="line">          name: http</span><br><span class="line">      volumes:</span><br><span class="line">      - name: proc</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /proc</span><br><span class="line">      - name: dev</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /dev</span><br><span class="line">      - name: sys</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /sys</span><br><span class="line">      - name: rootfs</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /</span><br></pre></td></tr></table></figure></li>
</ol>
<p>部署之后通过 Grafana 导入 <a target="_blank" rel="noopener" href="https://grafana.com/grafana/dashboards/8919">8919 Dashboard</a>，可以通过 <code>node exporter</code> 实现采集 node 节点上的监控数据。</p>
<p>如果部署之后，Dashboard 显示无数据，需要排查 <code>node-exporter</code> 相关的 <code>Service</code>，<code>EndPoint</code> 是否正常。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get services -n prometheus</span></span><br><span class="line">NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE</span><br><span class="line">node-exporter        ClusterIP   10.102.48.208   &lt;none&gt;        9100/TCP            44m</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get endpoints -n prometheus</span></span><br><span class="line">NAME                 ENDPOINTS                             AGE</span><br><span class="line">node-exporter        10.244.3.107:9100,10.244.4.64:9100    49m</span><br></pre></td></tr></table></figure>

<h2 id="配置-Prometheus-支持-Kubernetes-服务发现"><a href="#配置-Prometheus-支持-Kubernetes-服务发现" class="headerlink" title="配置 Prometheus 支持 Kubernetes 服务发现"></a>配置 Prometheus 支持 Kubernetes 服务发现</h2><p>在 Kubernetes 下，Promethues 通过与 Kubernetes API 集成目前主要支持5种服务发现模式，分别是： <sup id="fnref:3"><a href="#fn:3" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="[Kubernetes 服务发现](https://yunlzheng.gitbook.io/prometheus-book/part-iii-prometheus-shi-zhan/readmd/service-discovery-with-kubernetes#fu-wu-fa-xian)">[3]</span></a></sup></p>
<ul>
<li><code>Node</code></li>
<li><code>Service</code></li>
<li><code>Pod</code></li>
<li><code>Endpoints</code></li>
<li><code>Ingress</code></li>
</ul>
<h3 id="配置-Prometheus-支持-Kubernetes-节点自动发现并抓取监控指标"><a href="#配置-Prometheus-支持-Kubernetes-节点自动发现并抓取监控指标" class="headerlink" title="配置 Prometheus 支持 Kubernetes 节点自动发现并抓取监控指标"></a>配置 Prometheus 支持 Kubernetes 节点自动发现并抓取监控指标</h3><p>为了让 Prometheus 能够获取到当前集群中所有节点的信息，在 Promtheus 的配置文件中，添加如下 Job 配置：</p>
<figure class="highlight shell"><figcaption><span>/etc/prometheus/prometheus.yml</span></figcaption><table><tr><td class="code"><pre><span class="line">- job_name: &#x27;kubernetes-nodes&#x27;</span><br><span class="line">  tls_config:</span><br><span class="line">    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: node</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - source_labels: [__address__]</span><br><span class="line">    regex: &#x27;(.*):10250&#x27;</span><br><span class="line">    replacement: &#x27;$&#123;1&#125;:9100&#x27;</span><br><span class="line">    target_label: __address__</span><br><span class="line">    action: replace</span><br></pre></td></tr></table></figure>
<p>通过指定 <code>kubernetes_sd_config</code> 的模式为 <code>node</code>，Prometheus 会自动从 Kubernetes 中发现到所有的 node 节点并作为当前 Job 监控的 Target 实例。这里需要指定用于 <a href="/202304271425/" title="访问 Kubernetes API 的 ca 以及 token 文件路径">访问 Kubernetes API 的 ca 以及 token 文件路径</a>。</p>
<p>通过以上配置，Prometheus 可以自动从 Kubernetes API Server 中发现节点的信息，并将其作为当前 Job 的 Target 实例，此配置下默认只存在 2 个标签<br><img src="https://i.csms.tech/img_155.png"></p>
<p>要将节点中的所有标签添加到 Prometheus 监控指标中，可以添加以下 <code>labelmap</code> 配置，意思为将正则表达式 <code>__meta_kubernetes_node_label_(.+)</code> 匹配的数据也添加到指标数据的 Lable 中去。</p>
<figure class="highlight shell"><figcaption><span>/etc/prometheus/prometheus.yml</span></figcaption><table><tr><td class="code"><pre><span class="line">- job_name: &#x27;kubernetes-nodes&#x27;</span><br><span class="line">  tls_config:</span><br><span class="line">    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: node</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - source_labels: [__address__]</span><br><span class="line">    regex: &#x27;(.*):10250&#x27;</span><br><span class="line">    replacement: &#x27;$&#123;1&#125;:9100&#x27;</span><br><span class="line">    target_label: __address__</span><br><span class="line">    action: replace</span><br><span class="line">  - action: labelmap</span><br><span class="line">    regex: __meta_kubernetes_node_label_(.+)</span><br></pre></td></tr></table></figure>
<p>以上配置生效后，重新查看节点的标签信息，可以看到节点的的标签已经添加到了 Prometheus 监控指标中。<br><img src="https://i.csms.tech/img_156.png"></p>
<p>对于 <code>kubernetes_sd_configs</code> 下面可用的元信息标签如下：</p>
<ul>
<li><code>__meta_kubernetes_node_name</code> ：节点对象的名称</li>
<li><code>__meta_kubernetes_node_label</code> ：节点对象中的每个标签</li>
<li><code>__meta_kubernetes_node_annotation</code> ：来自节点对象的每个注释</li>
<li><code>__meta_kubernetes_node_address</code> ：每个节点地址类型的第一个地址（如果存在）</li>
</ul>
<h3 id="配置-Prometheus-自动发现-kube-apiserver-并读取监控指标"><a href="#配置-Prometheus-自动发现-kube-apiserver-并读取监控指标" class="headerlink" title="配置 Prometheus 自动发现 kube-apiserver 并读取监控指标"></a>配置 Prometheus 自动发现 kube-apiserver 并读取监控指标</h3><p><code>kube-apiserver</code> 监听在节点的 6443 端口，通过以下配置可以使 Prometheus 读取 <code>kube-apiserver</code> 的指标数据</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">- job_name: &quot;kubernetes-apiservers&quot;</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">    - role: endpoints</span><br><span class="line">  scheme: https</span><br><span class="line">  tls_config:</span><br><span class="line">    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">  relabel_configs:</span><br><span class="line">    - source_labels:</span><br><span class="line">        [</span><br><span class="line">          __meta_kubernetes_namespace,</span><br><span class="line">          __meta_kubernetes_service_name,</span><br><span class="line">          __meta_kubernetes_endpoint_port_name,</span><br><span class="line">        ]</span><br><span class="line">      action: keep</span><br><span class="line">      regex: default;kubernetes;https</span><br></pre></td></tr></table></figure>

<h3 id="配置-Prometheus-自动发现-kubelet-并读取监控指标"><a href="#配置-Prometheus-自动发现-kubelet-并读取监控指标" class="headerlink" title="配置 Prometheus 自动发现 kubelet 并读取监控指标"></a>配置 Prometheus 自动发现 kubelet 并读取监控指标</h3><p>kubelet 监听在节点的 10250 端口，通过以下配置可以使 Prometheus 读取 <code>kubelet</code> 提供的监控数据。这里需要 <a href="#%E5%88%9B%E5%BB%BA%E9%9B%86%E7%BE%A4%E8%A7%92%E8%89%B2">配置好 <code>ServiceAccount</code>的权限，以使 Prometheus 有查询集群资源的权限</a>。</p>
<figure class="highlight shell"><figcaption><span>/etc/prometheus/prometheus.yml</span></figcaption><table><tr><td class="code"><pre><span class="line">global:</span><br><span class="line">  scrape_interval: 5s</span><br><span class="line">  evaluation_interval: 5s</span><br><span class="line"></span><br><span class="line">scrape_configs:</span><br><span class="line">  - job_name: &#x27;prometheus&#x27;</span><br><span class="line">    static_configs:</span><br><span class="line">    - targets: [&#x27;localhost:9090&#x27;]</span><br><span class="line">    </span><br><span class="line">  - job_name: &#x27;kubernetes-nodes&#x27;</span><br><span class="line">    tls_config:</span><br><span class="line">      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">    kubernetes_sd_configs:</span><br><span class="line">    - role: node</span><br><span class="line">    relabel_configs:</span><br><span class="line">    - source_labels: [__address__]</span><br><span class="line">      regex: &#x27;(.*):10250&#x27;</span><br><span class="line">      replacement: &#x27;$&#123;1&#125;:9100&#x27;</span><br><span class="line">      target_label: __address__</span><br><span class="line">      action: replace</span><br><span class="line">    - action: labelmap</span><br><span class="line">      regex: __meta_kubernetes_node_label_(.+)</span><br><span class="line"></span><br><span class="line">  - job_name: &#x27;kubernetes-kubelet&#x27;</span><br><span class="line">    kubernetes_sd_configs:</span><br><span class="line">    - role: node</span><br><span class="line">    scheme: https</span><br><span class="line">    tls_config:</span><br><span class="line">      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">      insecure_skip_verify: true</span><br><span class="line">    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">    relabel_configs:</span><br><span class="line">    - action: labelmap</span><br><span class="line">      regex: __meta_kubernetes_node_label_(.+)</span><br></pre></td></tr></table></figure>
<p>以上配置生效后，查看 Prometheus 的 Targets，会看到多了 <code>kubernetes-kubelet</code><br><img src="https://i.csms.tech/img_157.png"></p>
<p>但是请求监控数据错误，返回：<code>server returned HTTP status 403 Forbidden</code>。根据日志提示，可能是因为权限原因被拒绝。</p>
<p>Prometheus 请求 Kubelet 使用的是 Token 鉴权 <sup id="fnref:5"><a href="#fn:5" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="[Kubelet 鉴权](https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/kubelet-authn-authz/#kubelet-authorization)
">[5]</span></a></sup> 。基于 <a href="/202305161451/" title="Kubernetes API Server 的 RBAC">Kubernetes API Server 的 RBAC</a>，大体流程为： </p>
<ol>
<li>Pod 使用启动时系统挂载的 Token （<code>/var/run/secrets/kubernetes.io/serviceaccount/token</code>）向 kubelet 发起查询请求。 Prometheus 使用的 Token 路径是在配置文件中指定 <code>bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</code> </li>
<li>Kubelet 校验 Token 的权限</li>
</ol>
<p>根据错误消息，可以猜测 Token 权限存在问题。以下步骤针对此猜测进行验证，<a href="/202305161451/" title="其原理参考文档">其原理参考文档</a></p>
<ol>
<li>登陆到 Prometheus 所在的 Pod，执行以下命令，模拟请求 Kubelet，从响应可以看到 <code>Forbidden (user=system:serviceaccount:prometheus:default, verb=get, resource=nodes, subresource=metrics)</code>，说明 Pod 使用的 <code>user=system:serviceaccount:prometheus:default</code> ServiceAccount 账号没有权限，并且具体使用的权限为 <code>verb=get, resource=nodes, subresource=metrics</code><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -v -k -H <span class="string">&quot;Authorization: Bearer `cat /var/run/secrets/kubernetes.io/serviceaccount/token`&quot;</span> https://172.31.19.164:10250/metrics</span></span><br><span class="line">*   Trying 172.31.19.164:10250...</span><br><span class="line">* Connected to 172.31.19.164 (172.31.19.164) port 10250 (#0)</span><br><span class="line">* using HTTP/2</span><br><span class="line">* h2h3 [:method: GET]</span><br><span class="line">* h2h3 [:path: /metrics]</span><br><span class="line">* h2h3 [:scheme: https]</span><br><span class="line">* h2h3 [:authority: 172.31.19.164:10250]</span><br><span class="line">* h2h3 [user-agent: curl/8.0.1]</span><br><span class="line">* h2h3 [accept: */*]</span><br><span class="line">* h2h3 [authorization: Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6Ik51eFpuNU9MUlp2QkxmWjlxRVpVMjRYYVRpV3RSQk1HanJsRnBjbjJBSzQifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNzE2OTcwODc5LCJpYXQiOjE2ODU0MzQ4NzksImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlc]</span><br><span class="line">* Using Stream ID: 1 (easy handle 0x7f1038310af0)</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">GET /metrics HTTP/2</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">Host: 172.31.19.164:10250</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">user-agent: curl/8.0.1</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">accept: */*</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">authorization: Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6Ik51eFpuNU9MUlp2QkxmWjlxRVpVMjRYYVRpV3RSQk1HanJsRnBjbjJBSzQifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNzE2OTcwODc5LCJpYXQiOjE2ODU0MzQ4NzksImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlc]</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash">* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4):</span></span><br><span class="line">&lt; HTTP/2 403 </span><br><span class="line">&lt; content-type: text/plain; charset=utf-8</span><br><span class="line">&lt; content-length: 104</span><br><span class="line">&lt; date: Tue, 30 May 2023 08:22:34 GMT</span><br><span class="line">&lt; </span><br><span class="line">* Connection #0 to host 172.31.19.164 left intact</span><br><span class="line">Forbidden (user=system:serviceaccount:prometheus:default, verb=get, resource=nodes, subresource=metrics)</span><br></pre></td></tr></table></figure></li>
<li>检查 Prometheus Namespace 中的默认的 ServiceAccount 绑定的权限，其绑定到了名为 <code>prometheus</code> 的 ClusterRole <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl edit clusterrolebinding prometheus</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: prometheus</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: default</span><br><span class="line">  namespace: prometheus</span><br></pre></td></tr></table></figure></li>
<li>检查名为 <code>prometheus</code> 的 ClusterRole 的权限信息，可以看到其中没有对 <code>verb=get, resource=nodes, subresource=metrics</code> 的授权，将其添加到授权中，重新查看 Prometheus 的 Targets 中 <code>kubernetes-kubelet</code> 的状态，请求正常。<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl edit clusterrole prometheus</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - nodes</span><br><span class="line">  - nodes/proxy</span><br><span class="line">  - nodes/metrics</span><br><span class="line">  - services</span><br><span class="line">  - endpoints</span><br><span class="line">  - pods</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">- apiGroups:</span><br><span class="line">  - extensions</span><br><span class="line">  resources:</span><br><span class="line">  - ingresses</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">- nonResourceURLs:</span><br><span class="line">  - /metrics</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br></pre></td></tr></table></figure>
<img src="https://i.csms.tech/img_158.png"></li>
</ol>
<h3 id="配置-Prometheus-从-cAdvisor-读取监控数据"><a href="#配置-Prometheus-从-cAdvisor-读取监控数据" class="headerlink" title="配置 Prometheus 从 cAdvisor 读取监控数据"></a>配置 Prometheus 从 cAdvisor 读取监控数据</h3><p>各节点的 kubelet 组件中除了包含自身的监控指标信息以外，kubelet 组件还内置了对 cAdvisor 的支持。cAdvisor 能够获取当前节点上运行的所有容器的资源使用情况，通过访问 kubelet 的 <code>/metrics/cadvisor</code> 地址可以获取到 cadvisor 的监控指标，因此和获取 kubelet 监控指标类似，这里同样通过 node 模式自动发现所有的 kubelet 信息，并通过适当的 <code>relabel</code> 过程，修改监控采集任务的配置</p>
<figure class="highlight shell"><figcaption><span>/etc/prometheus/prometheus.yml</span></figcaption><table><tr><td class="code"><pre><span class="line">global:</span><br><span class="line">  scrape_interval: 5s</span><br><span class="line">  evaluation_interval: 5s</span><br><span class="line"></span><br><span class="line">scrape_configs:</span><br><span class="line">  - job_name: &#x27;prometheus&#x27;</span><br><span class="line">    static_configs:</span><br><span class="line">    - targets: [&#x27;localhost:9090&#x27;]</span><br><span class="line">    </span><br><span class="line">  - job_name: &#x27;kubernetes-nodes&#x27;</span><br><span class="line">    tls_config:</span><br><span class="line">      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">    kubernetes_sd_configs:</span><br><span class="line">    - role: node</span><br><span class="line">    relabel_configs:</span><br><span class="line">    - source_labels: [__address__]</span><br><span class="line">      regex: &#x27;(.*):10250&#x27;</span><br><span class="line">      replacement: &#x27;$&#123;1&#125;:9100&#x27;</span><br><span class="line">      target_label: __address__</span><br><span class="line">      action: replace</span><br><span class="line">    - action: labelmap</span><br><span class="line">      regex: __meta_kubernetes_node_label_(.+)</span><br><span class="line"></span><br><span class="line">  - job_name: &#x27;kubernetes-kubelet&#x27;</span><br><span class="line">    kubernetes_sd_configs:</span><br><span class="line">    - role: node</span><br><span class="line">    scheme: https</span><br><span class="line">    tls_config:</span><br><span class="line">      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">      insecure_skip_verify: true</span><br><span class="line">    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">    relabel_configs:</span><br><span class="line">    - action: labelmap</span><br><span class="line">      regex: __meta_kubernetes_node_label_(.+)</span><br><span class="line">      </span><br><span class="line">  - job_name: &#x27;kubernetes-cadvisor&#x27;</span><br><span class="line">    scheme: https</span><br><span class="line">    tls_config:</span><br><span class="line">      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">      insecure_skip_verify: true</span><br><span class="line">    kubernetes_sd_configs:</span><br><span class="line">    - role: node</span><br><span class="line">    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">    relabel_configs:</span><br><span class="line">    - source_labels: [__meta_kubernetes_node_name]</span><br><span class="line">      regex: (.+)</span><br><span class="line">      target_label: __metrics_path__</span><br><span class="line">      replacement: metrics/cadvisor</span><br><span class="line">    - action: labelmap</span><br><span class="line">      regex: __meta_kubernetes_node_label_(.+)</span><br></pre></td></tr></table></figure>
<p>以上配置生效后，查看 Prometheus 的 Targets 信息，正常会看到 cAdvisor 的 Target</p>
<p><img src="https://i.csms.tech/img_159.png"></p>
<h3 id="配置-Prometheus-抓取-Kubernetes-集群资源状态指标"><a href="#配置-Prometheus-抓取-Kubernetes-集群资源状态指标" class="headerlink" title="配置 Prometheus 抓取 Kubernetes 集群资源状态指标"></a>配置 Prometheus 抓取 Kubernetes 集群资源状态指标</h3><p>要监控 Kubernetes 集群资源状态的相关指标，需要在 Kubernetes 中 <a href="https://csms.tech/202209121102/#部署-kube-state-metrics-组件">部署 <code>kube-state-metrics</code> 组件</a>。</p>
<p>在 Prometheus 配置文件中，添加一个新的监控目标以获取 <code>kube-state-metrics</code> 抓取的指标</p>
<figure class="highlight shell"><figcaption><span>/etc/prometheus/prometheus.yml</span></figcaption><table><tr><td class="code"><pre><span class="line">global:</span><br><span class="line">  scrape_interval: 5s</span><br><span class="line">  evaluation_interval: 5s</span><br><span class="line"></span><br><span class="line">scrape_configs:</span><br><span class="line">  - job_name: &#x27;prometheus&#x27;</span><br><span class="line">    static_configs:</span><br><span class="line">    - targets: [&#x27;localhost:9090&#x27;]</span><br><span class="line">    </span><br><span class="line">  - job_name: &#x27;kubernetes-nodes&#x27;</span><br><span class="line">    tls_config:</span><br><span class="line">      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">    kubernetes_sd_configs:</span><br><span class="line">    - role: node</span><br><span class="line">    relabel_configs:</span><br><span class="line">    - source_labels: [__address__]</span><br><span class="line">      regex: &#x27;(.*):10250&#x27;</span><br><span class="line">      replacement: &#x27;$&#123;1&#125;:9100&#x27;</span><br><span class="line">      target_label: __address__</span><br><span class="line">      action: replace</span><br><span class="line">    - action: labelmap</span><br><span class="line">      regex: __meta_kubernetes_node_label_(.+)</span><br><span class="line"></span><br><span class="line">  - job_name: &#x27;kubernetes-kubelet&#x27;</span><br><span class="line">    kubernetes_sd_configs:</span><br><span class="line">    - role: node</span><br><span class="line">    scheme: https</span><br><span class="line">    tls_config:</span><br><span class="line">      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">      insecure_skip_verify: true</span><br><span class="line">    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">    relabel_configs:</span><br><span class="line">    - action: labelmap</span><br><span class="line">      regex: __meta_kubernetes_node_label_(.+)</span><br><span class="line">      </span><br><span class="line">  - job_name: &#x27;kubernetes-cadvisor&#x27;</span><br><span class="line">    scheme: https</span><br><span class="line">    tls_config:</span><br><span class="line">      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">      insecure_skip_verify: true</span><br><span class="line">    kubernetes_sd_configs:</span><br><span class="line">    - role: node</span><br><span class="line">    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">    relabel_configs:</span><br><span class="line">    - source_labels: [__meta_kubernetes_node_name]</span><br><span class="line">      regex: (.+)</span><br><span class="line">      target_label: __metrics_path__</span><br><span class="line">      replacement: metrics/cadvisor</span><br><span class="line">    - action: labelmap</span><br><span class="line">      regex: __meta_kubernetes_node_label_(.+)</span><br><span class="line">      </span><br><span class="line">  - job_name: &#x27;kube-state-metrics&#x27;</span><br><span class="line">    static_configs:</span><br><span class="line">    - targets: [&#x27;kube-state-metrics.kube-system.svc.cluster.local:8080&#x27;]  </span><br><span class="line">  </span><br></pre></td></tr></table></figure>
<p>要查看 <code>kube-state-metrics</code> 抓取的指标，可以在集群内访问 <code>kube-state-metrics.kube-system.svc.cluster.local:8080/metrics</code> 查看</p>
<h3 id="etcd-组件监控"><a href="#etcd-组件监控" class="headerlink" title="etcd 组件监控"></a>etcd 组件监控</h3><ol>
<li><p>修改 <code>etcd</code> 配置</p>
<p>Kubernetes 集群的 <code>etcd</code> 默认是开启暴露 <code>metrics</code> 数据的。查看 <code>etcd</code> 的 Pod 中容器的启动参数。其中 <code>--listen-metrics-urls=http://127.0.0.1:2381</code> 参数配置了 Metrics 接口运行在 <code>http://127.0.0.1:2381</code>。这里默认使用了 <code>127.0.0.1</code> 监听，需要修改（<strong>所有节点</strong>） <code>etcd</code> 的（静态 Pod）的配置文件 <code>/etc/kubernetes/manifests/etcd.yaml</code>，将 <code>- --listen-metrics-urls=http://127.0.0.1:2381</code> 修改为 Prometheus 可请求的 IP</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl get pods -n kube-system etcd -o yaml</span></span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - etcd</span><br><span class="line">    - --advertise-client-urls=https://172.31.26.116:2379</span><br><span class="line">    - --cert-file=/etc/kubernetes/pki/etcd/server.crt</span><br><span class="line">    - --client-cert-auth=true</span><br><span class="line">    - --data-dir=/var/lib/etcd</span><br><span class="line">    - --experimental-initial-corrupt-check=true</span><br><span class="line">    - --initial-advertise-peer-urls=https://172.31.26.116:2380</span><br><span class="line">    - --initial-cluster=fm-k8s-c1-master1=https://172.31.26.116:2380</span><br><span class="line">    - --key-file=/etc/kubernetes/pki/etcd/server.key</span><br><span class="line">    - --listen-client-urls=https://127.0.0.1:2379,https://172.31.26.116:2379</span><br><span class="line">    - --listen-metrics-urls=http://127.0.0.1:2381</span><br><span class="line">    - --listen-peer-urls=https://172.31.26.116:2380</span><br><span class="line">    - --name=k8s-master1</span><br><span class="line">    - --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt</span><br><span class="line">    - --peer-client-cert-auth=true</span><br><span class="line">    - --peer-key-file=/etc/kubernetes/pki/etcd/peer.key</span><br><span class="line">    - --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt</span><br><span class="line">    - --snapshot-count=10000</span><br><span class="line">    - --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt</span><br><span class="line">    image: k8s.gcr.io/etcd:3.5.3-0</span><br></pre></td></tr></table></figure></li>
<li><p>为 <code>etcd</code> 的 Pod 创建 <code>service</code></p>
<p>在 <a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/ha-topology/#stacked-etcd-topology">堆叠（Stacked）<code>etcd</code> 拓扑</a> 的高可用控制平面的架构下，<code>etcd</code> 通常会运行在每个 master 控制节点上（多实例）。为了方便 Prometheus 监控，可以为 <code>etcd</code> Pod 创建 <a href="https://csms.tech/202209241108/#Service">Headless Service</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: k8s-etcd</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  clusterIP: None  #设置为None，不分配Service IP</span><br><span class="line">  ports:</span><br><span class="line">  - port: 2381</span><br><span class="line">    targetPort: 2381</span><br><span class="line">    name: etcd-metrics-port</span><br><span class="line">  selector:</span><br><span class="line">    component: etcd</span><br></pre></td></tr></table></figure>
<p>创建成功后，可以检查以下 Service、Endpoints 信息是否正确。Service 没问题后，即可在 Prometheus 中通过 FQDN <code>k8s-etcd.kube-system.svc:2381/metrics</code> 抓取到 <code>etcd</code> 的指标。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl get pods -A -l component=etcd</span></span><br><span class="line">NAMESPACE     NAME                   READY   STATUS    RESTARTS      AGE</span><br><span class="line">kube-system   etcd-ops-k8s-master1   1/1     Running   1 (17m ago)   20m</span><br><span class="line">kube-system   etcd-ops-k8s-master2   1/1     Running   0             15m</span><br><span class="line">kube-system   etcd-ops-k8s-master3   1/1     Running   0             15m</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl get services -n kube-system</span></span><br><span class="line">NAME                 TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                  AGE</span><br><span class="line">k8s-etcd             ClusterIP   None           &lt;none&gt;        2381/TCP                 15s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl get endpoints -n kube-system</span></span><br><span class="line">NAME                 ENDPOINTS                                                AGE</span><br><span class="line">k8s-etcd             172.31.19.164:2381,172.31.21.3:2381,172.31.26.116:2381   33s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl get pods -n kube-system -o wide</span></span><br><span class="line">NAME                                      READY   STATUS    RESTARTS       AGE    IP              NODE                NOMINATED NODE   READINESS GATES</span><br><span class="line">etcd-ops-k8s-master1                      1/1     Running   1 (27m ago)    30m    172.31.26.116   ops-k8s-master1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">etcd-ops-k8s-master2                      1/1     Running   0              25m    172.31.19.164   ops-k8s-master2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">etcd-ops-k8s-master3                      1/1     Running   0              25m    172.31.21.3     ops-k8s-master3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">curl -v k8s-etcd.kube-system.svc:2381/metrics</span></span><br><span class="line">*   Trying 172.31.26.116:2381...</span><br><span class="line">* Connected to k8s-etcd.kube-system.svc (172.31.26.116) port 2381 (#0)</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">GET /metrics HTTP/1.1</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">Host: k8s-etcd.kube-system.svc:2381</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">User-Agent: curl/7.80.0</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">Accept: */*</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash">* Mark bundle as not supporting multiuse</span></span><br><span class="line">&lt; HTTP/1.1 200 OK</span><br><span class="line">&lt; Content-Type: text/plain; version=0.0.4; charset=utf-8</span><br><span class="line">&lt; Date: Wed, 04 Oct 2023 02:15:01 GMT</span><br><span class="line">&lt; Transfer-Encoding: chunked</span><br><span class="line">&lt; </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">HELP etcd_cluster_version Which version is running. 1 <span class="keyword">for</span> <span class="string">&#x27;cluster_version&#x27;</span> label with current cluster version</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">TYPE etcd_cluster_version gauge</span></span><br><span class="line">etcd_cluster_version&#123;cluster_version=&quot;3.5&quot;&#125; 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">HELP etcd_debugging_auth_revision The current revision of auth store.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">TYPE etcd_debugging_auth_revision gauge</span></span><br><span class="line">etcd_debugging_auth_revision 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">HELP etcd_debugging_disk_backend_commit_rebalance_duration_seconds The latency distributions of commit.rebalance called by bboltdb backend.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">TYPE etcd_debugging_disk_backend_commit_rebalance_duration_seconds histogram</span></span><br><span class="line">etcd_debugging_disk_backend_commit_rebalance_duration_seconds_bucket&#123;le=&quot;0.001&quot;&#125; 5155</span><br><span class="line">etcd_debugging_disk_backend_commit_rebalance_duration_seconds_bucket&#123;le=&quot;0.002&quot;&#125; 5155</span><br><span class="line">etcd_debugging_disk_backend_commit_rebalance_duration_seconds_bucket&#123;le=&quot;0.004&quot;&#125; 5155</span><br><span class="line">etcd_debugging_disk_backend_commit_rebalance_duration_seconds_bucket&#123;le=&quot;0.008&quot;&#125; 5155</span><br><span class="line">etcd_debugging_disk_backend_commit_rebalance_duration_seconds_bucket&#123;le=&quot;0.016&quot;&#125; 5155</span><br></pre></td></tr></table></figure></li>
<li><p>Prometheus 中添加抓取 <code>etcd</code> 指标的配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">- job_name: &#x27;kube-etcd&#x27;</span><br><span class="line">  metrics_path: /metrics</span><br><span class="line">  scheme: http</span><br><span class="line">  tls_config:</span><br><span class="line">    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: endpoints</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - source_labels: [__meta_kubernetes_service_name]</span><br><span class="line">    regex: k8s-etcd</span><br><span class="line">    action: keep</span><br><span class="line">  - action: labelmap</span><br><span class="line">    regex: __meta_kubernetes_pod_label_(.+)</span><br></pre></td></tr></table></figure></li>
<li><p>Prometheus 中检查是否抓取到了 <code>etcd</code> 指标<br><img src="https://i.csms.tech/img_222.png"></p>
</li>
</ol>
<h3 id="Scheduler-组件监控"><a href="#Scheduler-组件监控" class="headerlink" title="Scheduler 组件监控"></a>Scheduler 组件监控</h3><ol>
<li><p>修改 Scheduler 监听 IP 地址</p>
<p> Scheduler 组件默认监听在 <code>127.0.0.1:10259</code>（<code>hostNetwork: true</code> 类型的网络，监听在主机 network Namespace）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">netstat -anutp | grep -v -E <span class="string">&quot;TIME_WAIT|ESTABLISHED&quot;</span> | grep schedule</span></span><br><span class="line">tcp        0      0 127.0.0.1:10259         0.0.0.0:*               LISTEN      24770/kube-schedule</span><br></pre></td></tr></table></figure>
<p>修改 <strong>所有 Master 节点</strong> 上的 <code>kube-scheduler</code> 配置 <code>/etc/kubernetes/manifests/kube-scheduler.yaml</code>，将监听地址修改为 <code>- --bind-address=0.0.0.0</code></p>
<figure class="highlight shell"><figcaption><span>/etc/kubernetes/manifests/kube-scheduler.yaml</span></figcaption><table><tr><td class="code"><pre><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-scheduler</span><br><span class="line">    - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf</span><br><span class="line">    - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf</span><br><span class="line">    - --bind-address=0.0.0.0</span><br><span class="line">    - --kubeconfig=/etc/kubernetes/scheduler.conf</span><br><span class="line">    - --leader-elect=true</span><br><span class="line">    image: k8s.gcr.io/kube-scheduler:v1.24.8</span><br></pre></td></tr></table></figure>
<p>修改后，<code>kube-scheduler</code> 的 Pod 会自动重启（静态 Pod），重启后 <code>kube-scheduler</code> 会监听所有 IP 地址</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">netstat -anutp | grep -v -E <span class="string">&quot;TIME_WAIT|ESTABLISHED&quot;</span> | grep schedule</span></span><br><span class="line">tcp6       0      0 :::10259                :::*                    LISTEN      27244/kube-schedule</span><br></pre></td></tr></table></figure></li>
<li><p>为 <code>kube-scheduler</code> 的 Pod 创建 <code>service</code></p>
<p>参考以下配置，为 <code>kube-scheduler</code> 的 Pod 创建 <code>service</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: k8s-scheduler</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  clusterIP: None  #设置为None，不分配Service IP</span><br><span class="line">  ports:</span><br><span class="line">  - port: 10259</span><br><span class="line">    targetPort: 10259</span><br><span class="line">    name: k8s-scheduler-metrics-port</span><br><span class="line">  selector:</span><br><span class="line">    component: kube-scheduler  </span><br></pre></td></tr></table></figure></li>
<li><p>Prometheus 中添加抓取 <code>kube-scheduler</code> 指标的配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">- job_name: &#x27;kube-scheduler&#x27;</span><br><span class="line">  metrics_path: metrics</span><br><span class="line">  scheme: https</span><br><span class="line">  tls_config:</span><br><span class="line">    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">    insecure_skip_verify: true</span><br><span class="line">  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: endpoints</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - source_labels: [__meta_kubernetes_service_name]</span><br><span class="line">    regex: k8s-scheduler</span><br><span class="line">    action: keep</span><br><span class="line">  - action: labelmap</span><br><span class="line">    regex: __meta_kubernetes_pod_label_(.+)</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="Controller-Manager-组件监控"><a href="#Controller-Manager-组件监控" class="headerlink" title="Controller Manager 组件监控"></a>Controller Manager 组件监控</h3><p>Controller Manager 组件默认监听 <code>127.0.0.1:10257</code>，修改 <code>kube-controller-manager</code> 配置 <code>/etc/kubernetes/manifests/kube-controller-manager.yaml</code>，将监听地址修改为 <code>- --bind-address=0.0.0.0</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">netstat -anutp | grep -v -E <span class="string">&quot;TIME_WAIT|ESTABLISHED&quot;</span> |grep contr</span></span><br><span class="line">tcp        0      0 127.0.0.1:10257         0.0.0.0:*               LISTEN      24786/kube-controll</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cat</span> /etc/kubernetes/manifests/kube-controller-manager.yaml</span></span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-controller-manager</span><br><span class="line">    - --allocate-node-cidrs=true</span><br><span class="line">    - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf</span><br><span class="line">    - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf</span><br><span class="line">    - --bind-address=0.0.0.0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">netstat -anutp | grep -v -E <span class="string">&quot;TIME_WAIT|ESTABLISHED&quot;</span> |grep contr</span></span><br><span class="line">tcp6       0      0 :::10257                :::*                    LISTEN      10489/kube-controll</span><br></pre></td></tr></table></figure>

<p>为 <code>kube-controller-manager</code> 创建 <code>service</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: k8s-controller-manager</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  clusterIP: None  #设置为None，不分配Service IP</span><br><span class="line">  ports:</span><br><span class="line">  - port: 10257</span><br><span class="line">    targetPort: 10257</span><br><span class="line">    name: k8s-controller-manager-metrics-port</span><br><span class="line">  selector:</span><br><span class="line">    component: kube-controller-manager</span><br></pre></td></tr></table></figure>
<p>Prometheus 中添加抓取 <code>kube-controller-manager</code> 指标的配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">- job_name: &#x27;kube-controller-manager&#x27;</span><br><span class="line">  metrics_path: metrics</span><br><span class="line">  scheme: https</span><br><span class="line">  tls_config:</span><br><span class="line">    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">    insecure_skip_verify: true</span><br><span class="line">  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: endpoints</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - source_labels: [__meta_kubernetes_service_name]</span><br><span class="line">    regex: k8s-controller-manager</span><br><span class="line">    action: keep</span><br><span class="line">  - action: labelmap</span><br><span class="line">    regex: __meta_kubernetes_pod_label_(.+)</span><br></pre></td></tr></table></figure>
<h3 id="kube-proxy-组件监控"><a href="#kube-proxy-组件监控" class="headerlink" title="kube-proxy 组件监控"></a>kube-proxy 组件监控</h3><p><code>kube-proxy</code> 的 Metrics 默认监听在 <code>127.0.0.1:10249</code>，执行命令 <code>kubectl edit configmap kube-proxy -n kube-system</code> 修改其监听地址</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">metricsBindAddress: &quot;0.0.0.0:10249&quot;</span><br></pre></td></tr></table></figure>
<p>修改配置后，重启 <code>kube-proxy</code>，检查监听地址，确定为 <code>:::10249</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl get pods -n kube-system</span></span><br><span class="line">NAME                                  READY   STATUS    RESTARTS        AGE</span><br><span class="line">kube-proxy-2cslw                      1/1     Running   8               301d</span><br><span class="line">kube-proxy-5nl5v                      1/1     Running   3               301d</span><br><span class="line">kube-proxy-m2b2x                      1/1     Running   3               301d</span><br><span class="line">kube-proxy-w5qh6                      1/1     Running   0               69s</span><br><span class="line">kube-proxy-zvrj4                      1/1     Running   3 (104d ago)    301d</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl delete pod -n kube-system kube-proxy-2cslw kube-proxy-5nl5v kube-proxy-m2b2x kube-proxy-zvrj4</span></span><br><span class="line">pod &quot;kube-proxy-2cslw&quot; deleted</span><br><span class="line">pod &quot;kube-proxy-5nl5v&quot; deleted</span><br><span class="line">pod &quot;kube-proxy-m2b2x&quot; deleted</span><br><span class="line">pod &quot;kube-proxy-zvrj4&quot; deleted</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">netstat -anutp | grep -v -E <span class="string">&quot;TIME_WAIT|ESTABLISHED&quot;</span> | grep pro</span></span><br><span class="line">tcp6       0      0 :::10249                :::*                    LISTEN      25831/kube-proxy    </span><br><span class="line">tcp6       0      0 :::10256                :::*                    LISTEN      25831/kube-proxy</span><br></pre></td></tr></table></figure>

<p>为 <code>kube-proxy</code> 创建 <code>service</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-proxy</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  clusterIP: None  #设置为None，不分配Service IP</span><br><span class="line">  ports:</span><br><span class="line">  - port: 10249</span><br><span class="line">    targetPort: 10249</span><br><span class="line">    name: kube-proxy-metrics-port</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kube-proxy</span><br></pre></td></tr></table></figure>

<p>Prometheus 中添加抓取 <code>kube-proxy</code> 指标的配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">- job_name: &#x27;kube-proxy&#x27;</span><br><span class="line">  metrics_path: metrics</span><br><span class="line">  scheme: https</span><br><span class="line">  tls_config:</span><br><span class="line">    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">    insecure_skip_verify: true</span><br><span class="line">  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: endpoints</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - source_labels: [__meta_kubernetes_service_name]</span><br><span class="line">    regex: kube-proxy</span><br><span class="line">    action: keep</span><br><span class="line">  - action: labelmap</span><br><span class="line">    regex: __meta_kubernetes_pod_label_(.+)</span><br></pre></td></tr></table></figure>

<h3 id="CoreDNS-组件监控"><a href="#CoreDNS-组件监控" class="headerlink" title="CoreDNS 组件监控"></a>CoreDNS 组件监控</h3><p>CoreDNS 组件默认就开启了 Metrics 接口，Endpoint 为 <code>kube-dns.kube-system.svc:9153/metrics</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl get services -n kube-system</span></span><br><span class="line">NAME                     TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                  AGE</span><br><span class="line">kube-dns                 ClusterIP   10.96.0.10     &lt;none&gt;        53/UDP,53/TCP,9153/TCP   301d</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">bash-5.1# curl kube-dns.kube-system.svc:9153/metrics</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">HELP coredns_build_info A metric with a constant <span class="string">&#x27;1&#x27;</span> value labeled by version, revision, and goversion from <span class="built_in">which</span> CoreDNS was built.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">TYPE coredns_build_info gauge</span></span><br><span class="line">coredns_build_info&#123;goversion=&quot;go1.17.1&quot;,revision=&quot;13a9191&quot;,version=&quot;1.8.6&quot;&#125; 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">HELP coredns_cache_entries The number of elements <span class="keyword">in</span> the cache.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">TYPE coredns_cache_entries gauge</span></span><br><span class="line">coredns_cache_entries&#123;server=&quot;dns://:53&quot;,type=&quot;denial&quot;&#125; 333</span><br><span class="line">coredns_cache_entries&#123;server=&quot;dns://:53&quot;,type=&quot;success&quot;&#125; 63</span><br></pre></td></tr></table></figure>
<p>因此监控 CoreDNS 只需要使用 Prometheus 的服务发现添加抓取 CoreDNS 的相关配置即可。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">- job_name: &#x27;kube-dns&#x27;</span><br><span class="line">  metrics_path: metrics</span><br><span class="line">  scheme: http</span><br><span class="line">  tls_config:</span><br><span class="line">    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">    insecure_skip_verify: false</span><br><span class="line">  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: endpoints</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - source_labels: [__meta_kubernetes_service_name]</span><br><span class="line">    regex: kube-dns</span><br><span class="line">    action: keep</span><br><span class="line">  - source_labels: [__meta_kubernetes_endpoint_port_name]</span><br><span class="line">    regex: metrics</span><br><span class="line">    action: keep </span><br><span class="line">  - action: labelmap</span><br><span class="line">    regex: __meta_kubernetes_pod_label_(.+)</span><br></pre></td></tr></table></figure>


<h3 id="配置-Prometheus-抓取-Ingress-Nginx-指标"><a href="#配置-Prometheus-抓取-Ingress-Nginx-指标" class="headerlink" title="配置 Prometheus 抓取 Ingress-Nginx 指标"></a>配置 Prometheus 抓取 Ingress-Nginx 指标</h3><ol>
<li><p>参考 <code>ingress-nginx</code> 官方提供的 Prometheus 自动发现 <code>ingress-nginx</code> 的配置 <sup id="fnref:9"><a href="#fn:9" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="[ingress-nginx prometheus](https://github.com/kubernetes/ingress-nginx/blob/main/deploy/prometheus/prometheus.yaml)">[9]</span></a></sup></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">global:</span><br><span class="line">  scrape_interval: 10s</span><br><span class="line">scrape_configs:</span><br><span class="line">- job_name: &#x27;ingress-nginx-endpoints&#x27;</span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: pod</span><br><span class="line">    namespaces:</span><br><span class="line">      names:</span><br><span class="line">      - ingress-nginx</span><br><span class="line">  relabel_configs:</span><br><span class="line">  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]</span><br><span class="line">    action: keep</span><br><span class="line">    regex: true</span><br><span class="line">  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]</span><br><span class="line">    action: replace</span><br><span class="line">    target_label: __scheme__</span><br><span class="line">    regex: (https?)</span><br><span class="line">  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]</span><br><span class="line">    action: replace</span><br><span class="line">    target_label: __metrics_path__</span><br><span class="line">    regex: (.+)</span><br><span class="line">  - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]</span><br><span class="line">    action: replace</span><br><span class="line">    target_label: __address__</span><br><span class="line">    regex: ([^:]+)(?::\d+)?;(\d+)</span><br><span class="line">    replacement: $1:$2</span><br><span class="line">  - source_labels: [__meta_kubernetes_service_name]</span><br><span class="line">    regex: prometheus-server</span><br><span class="line">    action: drop</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置 <code>ingress-nginx</code> 的 Deployment，添加端口配置，本示例中 Ingress-Nginx 端口类型为 <code>hostNetwork: true</code>。如果 Ingress-Nginx 使用了 Service，需要配置 Service 暴露相关端口。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- containerPort: 10254</span><br><span class="line">  hostPort: 10254</span><br><span class="line">  name: prometheus</span><br><span class="line">  protocol: TCP</span><br></pre></td></tr></table></figure></li>
<li><p>配置 <code>ingress-nginx</code> 的 Deployment，添加 Pod 针对 Prometheus 监控的注释</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      annotations:</span><br><span class="line">        prometheus.io/scrape: &quot;true&quot;</span><br><span class="line">        prometheus.io/port: &quot;10254&quot;</span><br></pre></td></tr></table></figure></li>
</ol>
<p>部署后，在 Prometheus UI 中检查 <code>nginx_ingress.*</code> 相关指标<br><img src="https://i.csms.tech/img_177.png"></p>
<h1 id="常见错误"><a href="#常见错误" class="headerlink" title="常见错误"></a>常见错误</h1><h2 id="failed-to-list-v1-Pod-pods-is-forbidden-User-quot-system-serviceaccount-prometheus-default-quot-cannot-list-resource-quot-pods-quot-in-API-group-quot-quot-at-the-cluster-scope”"><a href="#failed-to-list-v1-Pod-pods-is-forbidden-User-quot-system-serviceaccount-prometheus-default-quot-cannot-list-resource-quot-pods-quot-in-API-group-quot-quot-at-the-cluster-scope”" class="headerlink" title="failed to list *v1.Pod: pods is forbidden: User &quot;system:serviceaccount:prometheus:default&quot; cannot list resource &quot;pods&quot; in API group &quot;&quot; at the cluster scope”"></a>failed to list *v1.Pod: pods is forbidden: User &quot;system:serviceaccount:prometheus:default&quot; cannot list resource &quot;pods&quot; in API group &quot;&quot; at the cluster scope”</h2><p>部署 Prometheus 后，无法访问，检查 Pod 日志，显示错误： <code>failed to list *v1.Pod: pods is forbidden: User \&quot;system:serviceaccount:prometheus:default\&quot; cannot list resource \&quot;pods\&quot; in API group \&quot;\&quot; at the cluster scope&quot;</code> <sup id="fnref:2"><a href="#fn:2" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="[Configure Prometheus for service discovery](https://uzimihsr.github.io/post/2022-11-28-kubernetes-prometheus-kube-state-metrics-cadvisor/)
">[2]</span></a></sup></p>
<p>根据输出，应该是因为 Namespace <code>prometheus</code>  中的 <code>ServiceAccount</code> 账号 <code>default</code> 无相关权限导致，此权限是于 <a href="#%E5%88%9B%E5%BB%BA%E9%9B%86%E7%BE%A4%E8%A7%92%E8%89%B2">此处配置</a>，检查相关账号权限。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl describe clusterrole prometheus</span></span><br><span class="line">Name:         prometheus</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">PolicyRule:</span><br><span class="line">  Resources             Non-Resource URLs  Resource Names  Verbs</span><br><span class="line">  ---------             -----------------  --------------  -----</span><br><span class="line">  endpoints             []                 []              [get list watch]</span><br><span class="line">  nodes/proxy           []                 []              [get list watch]</span><br><span class="line">  nodes                 []                 []              [get list watch]</span><br><span class="line">  pods                  []                 []              [get list watch]</span><br><span class="line">  services              []                 []              [get list watch]</span><br><span class="line">  ingresses.extensions  []                 []              [get list watch]</span><br><span class="line">                        [/metrics]         []              [get]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl describe clusterrolebinding prometheus</span></span><br><span class="line">Name:         prometheus</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">Role:</span><br><span class="line">  Kind:  ClusterRole</span><br><span class="line">  Name:  prometheus</span><br><span class="line">Subjects:</span><br><span class="line">  Kind            Name     Namespace</span><br><span class="line">  ----            ----     ---------</span><br><span class="line">  ServiceAccount  default  prometheus</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>正常配置的 RBAC 账号输出如上，如果权限显示异常，需要重新检查 <a href="#%E5%88%9B%E5%BB%BA%E9%9B%86%E7%BE%A4%E8%A7%92%E8%89%B2">此处配置</a> 是否正常，如文件格式是否正确。本示例中是因为 yaml 文件格式导致 <code>clusterrolebinding</code> 绑定异常，输出结果如下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl describe clusterrolebinding prometheus</span></span><br><span class="line">Name:         prometheus</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">Role:</span><br><span class="line">  Kind:  ClusterRole</span><br><span class="line">  Name:  prometheus</span><br><span class="line">Subjects:</span><br><span class="line">  Kind            Name     Namespace</span><br><span class="line">  ----            ----     ---------</span><br></pre></td></tr></table></figure>
<p>更正文件格式后，重新 <code>kubectl apply</code> ，Prometheus Server 部署正常。</p>
<h2 id="server-returned-HTTP-status-400-Bad-Request"><a href="#server-returned-HTTP-status-400-Bad-Request" class="headerlink" title="server returned HTTP status 400 Bad Request"></a>server returned HTTP status 400 Bad Request</h2><p>Prometheus 配置服务自动发现监控 Kubernetes 的 Node 后，Node 状态显示为 <code>DOWN</code>，Error 为 <code>server returned HTTP status 400 Bad Request</code><br><img src="https://i.csms.tech/img_152.png"><br>这个是因为 prometheus 去发现 Node 模式的服务的时候，访问的端口默认是10250。而默认是需要认证的 https 协议才有权访问的，但实际上我们并不是希望让去访问 10250 端口的 <code>/metrics</code> 接口，而是 <code>node-exporter</code> 绑定到节点的 9100 端口，所以我们应该将这里的 10250 替换成 9100。 <sup id="fnref:4"><a href="#fn:4" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="[服务发现](https://www.qikqiak.com/k8strain/monitor/prometheus/#_8)
">[4]</span></a></sup></p>
<h2 id="opening-storage-failed-lock-DB-directory-resource-temporarily-unavailable"><a href="#opening-storage-failed-lock-DB-directory-resource-temporarily-unavailable" class="headerlink" title="opening storage failed: lock DB directory: resource temporarily unavailable"></a>opening storage failed: lock DB directory: resource temporarily unavailable</h2><p>Prometheus Server 无法启动，查看 Pod 日志，显示以下错误</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl logs prometheus-deployment-6967df46c6-znj2k -n prometheus</span></span><br><span class="line">ts=2023-05-27T09:22:14.967Z caller=main.go:1155 level=error err=&quot;opening storage failed: lock DB directory: resource temporarily unavailable&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>解决方法</strong> ： 删除 Prometheus Server 数据目录下的 <code>lock</code> 文件，重新启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span></span></span><br><span class="line">01H1CXS2BWTCBWA08HK9EFQ0FJ  01H1DBGBZP5SF2ENGTQV1CRVNM  01H1DS7Y4HQ9NPRDXEPYPM9BD0  01H1E6Z9Z1KTWCSDW75H3JW6Q7  lock            wal</span><br><span class="line">01H1D4MMQMSZHMQ31NN976SXEX  01H1DJC6WRMKJTGSTFQX262D75  01H1E03HZG28CZKB9YM0ZQPJ57  chunks_head                 queries.active</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">rm</span> -rf lock</span></span><br></pre></td></tr></table></figure>

<h2 id="cAdvisor-获取-Pod-指标元数据异常"><a href="#cAdvisor-获取-Pod-指标元数据异常" class="headerlink" title="cAdvisor 获取 Pod 指标元数据异常"></a>cAdvisor 获取 Pod 指标元数据异常</h2><h3 id="环境信息"><a href="#环境信息" class="headerlink" title="环境信息"></a>环境信息</h3><ul>
<li>Centos 7</li>
<li>Kubernetes 1.24</li>
<li>Prometheus 2.44.0</li>
<li>Docker Engine - Community 20.10.9</li>
<li>containerd containerd.io 1.6.9</li>
</ul>
<p>在 Prometheus UI 中查询指标 <code>container_network_transmit_bytes_total</code>，输出中没有 <code>container</code>、<code>name</code>、<code>pod</code> 等指标，甚至未输出 Pod 的网卡流量的指标。<br><img src="https://i.csms.tech/img_176.png"></p>
<p><code>container_network_transmit_bytes_total</code> 指标是 Kubelet 从 cAdvisor 中读取到的，为了排查问题出现的地方，尝试直接访问 Kubelet 获取此指标的数据</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -k -H <span class="string">&quot;Authorization: Bearer `cat /var/run/secrets/kubernetes.io/serviceaccount/token`&quot;</span> https://172.31.26.116</span></span><br><span class="line">:10250/metrics/cadvisor | grep container_network_transmit_bytes_total</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">TYPE container_network_transmit_bytes_total counter</span></span><br><span class="line">container_network_transmit_bytes_total&#123;container=&quot;&quot;,id=&quot;/&quot;,image=&quot;&quot;,interface=&quot;cni0&quot;,name=&quot;&quot;,namespace=&quot;&quot;,pod=&quot;&quot;&#125; 7.29571749e+09 1686126675185</span><br><span class="line">container_network_transmit_bytes_total&#123;container=&quot;&quot;,id=&quot;/&quot;,image=&quot;&quot;,interface=&quot;eth0&quot;,name=&quot;&quot;,namespace=&quot;&quot;,pod=&quot;&quot;&#125; 1.639010015553e+12 1686126675185</span><br><span class="line">container_network_transmit_bytes_total&#123;container=&quot;&quot;,id=&quot;/&quot;,image=&quot;&quot;,interface=&quot;flannel.1&quot;,name=&quot;&quot;,namespace=&quot;&quot;,pod=&quot;&quot;&#125; 7.967725528e+09 1686126675185</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>从结果可以看到，Kubelet 就未获取到相关指标及标签。Kubelet 是从 cAdvisor 获取到的容器的 Lables。如果是 Docker，主要是读取容器的 Inspect 信息获取标签（<code>Config.Labels</code>），检查容器的 Inspect 信息，发现是存在完整的 Lables 信息 <sup id="fnref:8"><a href="#fn:8" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="[cAdvisor获取Pod指标元数据异常](https://juejin.cn/post/7208349474841198650)
">[8]</span></a></sup></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker inspect 6b2b9d1b3a62</span></span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Id&quot;: &quot;6b2b9d1b3a62a9d070656841aaeb1bb0c43a83025295d69ec8d47618c717290b&quot;,</span><br><span class="line">        &quot;Created&quot;: &quot;2023-06-02T09:42:23.197361826Z&quot;,</span><br><span class="line">        &quot;Path&quot;: &quot;/coredns&quot;,</span><br><span class="line">        </span><br><span class="line">        &quot;Image&quot;: &quot;sha256:a4ca41631cc7ac19ce1be3ebf0314ac5f47af7c711f17066006db82ee3b75b03&quot;,</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        &quot;Config&quot;: &#123;</span><br><span class="line">            &quot;Hostname&quot;: &quot;coredns-6d4b75cb6d-fzxmc&quot;,</span><br><span class="line">            </span><br><span class="line">            &quot;ExposedPorts&quot;: &#123;</span><br><span class="line">                &quot;53/tcp&quot;: &#123;&#125;,</span><br><span class="line">                &quot;53/udp&quot;: &#123;&#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;Tty&quot;: false,</span><br><span class="line">            &quot;OpenStdin&quot;: false,</span><br><span class="line">            &quot;StdinOnce&quot;: false,</span><br><span class="line">            </span><br><span class="line">            &quot;Image&quot;: &quot;sha256:a4ca41631cc7ac19ce1be3ebf0314ac5f47af7c711f17066006db82ee3b75b03&quot;,</span><br><span class="line">            </span><br><span class="line">            &quot;Labels&quot;: &#123;</span><br><span class="line">                &quot;annotation.io.kubernetes.container.hash&quot;: &quot;6208af3e&quot;,</span><br><span class="line">                &quot;annotation.io.kubernetes.container.ports&quot;: &quot;[&#123;\&quot;name\&quot;:\&quot;dns\&quot;,\&quot;containerPort\&quot;:53,\&quot;protocol\&quot;:\&quot;UDP\&quot;&#125;,&#123;\&quot;name\&quot;:\&quot;dns-tcp\&quot;,\&quot;containerPort\&quot;:53,\&quot;protocol\&quot;:\&quot;TCP\&quot;&#125;,&#123;\&quot;name\&quot;:\&quot;metrics\&quot;,\&quot;containerPort\&quot;:9153,\&quot;protocol\&quot;:\&quot;TCP\&quot;&#125;]&quot;,</span><br><span class="line">                &quot;annotation.io.kubernetes.container.restartCount&quot;: &quot;11&quot;,</span><br><span class="line">                &quot;annotation.io.kubernetes.container.terminationMessagePath&quot;: &quot;/dev/termination-log&quot;,</span><br><span class="line">                &quot;annotation.io.kubernetes.container.terminationMessagePolicy&quot;: &quot;File&quot;,</span><br><span class="line">                &quot;annotation.io.kubernetes.pod.terminationGracePeriod&quot;: &quot;30&quot;,</span><br><span class="line">                &quot;io.kubernetes.container.logpath&quot;: &quot;/var/log/pods/kube-system_coredns-6d4b75cb6d-fzxmc_d46b52b3-e38d-4f57-938e-a454aa70c846/coredns/11.log&quot;,</span><br><span class="line">                &quot;io.kubernetes.container.name&quot;: &quot;coredns&quot;,</span><br><span class="line">                &quot;io.kubernetes.docker.type&quot;: &quot;container&quot;,</span><br><span class="line">                &quot;io.kubernetes.pod.name&quot;: &quot;coredns-6d4b75cb6d-fzxmc&quot;,</span><br><span class="line">                &quot;io.kubernetes.pod.namespace&quot;: &quot;kube-system&quot;,</span><br><span class="line">                &quot;io.kubernetes.pod.uid&quot;: &quot;d46b52b3-e38d-4f57-938e-a454aa70c846&quot;,</span><br><span class="line">                &quot;io.kubernetes.sandbox.id&quot;: &quot;1ce33bdb40f6498ce7bd9f61802b3b51e9e13aaf50184130a40578ef7562b5ca&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>从以上分析可以确定，问题应该是出在 cAdvisor 未获取到 Docker 容器中的 Labels 信息。</p>
<p>问题原因一直未找到，尝试 <a href="https://csms.tech/202209121102/#修改-kubelet-使用的-CRI-为-containerd">将 Kubelet 使用的 CRI 由 Docker 更改为 Containerd</a>，更改后，再次在 Prometheus UI 中查看 <code>container_network_transmit_bytes_total</code>，发现改 Containerd 作为 CRI 的 Kubelet 节点采集的指标标签中已经包含了 <code>Pod</code>、<code>namespace</code>、<code>image</code> 等标签</p>
<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a target="_blank" rel="noopener" href="https://zhangquan.me/2022/09/04/shi-yong-prometheus-jian-kong-kubernetes-ji-qun-jie-dian/">使用 Prometheus 监控 Kubernetes 集群节点</a></p>
<h1 id="脚注"><a href="#脚注" class="headerlink" title="脚注"></a>脚注</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/456205833">如何部署 Prometheus 监控K8S</a><a href="#fnref:1" rev="footnote"> ↩</a></span></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">2.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a target="_blank" rel="noopener" href="https://uzimihsr.github.io/post/2022-11-28-kubernetes-prometheus-kube-state-metrics-cadvisor/">Configure Prometheus for service discovery</a><a href="#fnref:2" rev="footnote"> ↩</a></span></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">3.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a target="_blank" rel="noopener" href="https://yunlzheng.gitbook.io/prometheus-book/part-iii-prometheus-shi-zhan/readmd/service-discovery-with-kubernetes#fu-wu-fa-xian">Kubernetes 服务发现</a><a href="#fnref:3" rev="footnote"> ↩</a></span></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">4.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a target="_blank" rel="noopener" href="https://www.qikqiak.com/k8strain/monitor/prometheus/#_8">服务发现</a><a href="#fnref:4" rev="footnote"> ↩</a></span></li><li id="fn:5"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">5.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/kubelet-authn-authz/#kubelet-authorization">Kubelet 鉴权</a><a href="#fnref:5" rev="footnote"> ↩</a></span></li><li id="fn:6"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">6.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a target="_blank" rel="noopener" href="http://www.mydlq.club/article/123/">Kubernetes 部署告警工具 AlertManager</a><a href="#fnref:6" rev="footnote"> ↩</a></span></li><li id="fn:7"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">7.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a target="_blank" rel="noopener" href="https://yunlzheng.gitbook.io/prometheus-book/parti-prometheus-ji-chu/alert/alert-manager-config">Alertmanager 配置概述</a><a href="#fnref:7" rev="footnote"> ↩</a></span></li><li id="fn:8"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">8.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a target="_blank" rel="noopener" href="https://juejin.cn/post/7208349474841198650">cAdvisor获取Pod指标元数据异常</a><a href="#fnref:8" rev="footnote"> ↩</a></span></li><li id="fn:9"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">9.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a target="_blank" rel="noopener" href="https://github.com/kubernetes/ingress-nginx/blob/main/deploy/prometheus/prometheus.yaml">ingress-nginx prometheus</a><a href="#fnref:9" rev="footnote"> ↩</a></span></li></ol></div></div>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="../tags/Prometheus/" rel="tag"><i class="fa fa-tag"></i> Prometheus</a>
              <a href="../tags/Kubernetes/" rel="tag"><i class="fa fa-tag"></i> Kubernetes</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="../202212071353/" rel="prev" title="kubernetes ConfigMap 使用说明">
                  <i class="fa fa-chevron-left"></i> kubernetes ConfigMap 使用说明
                </a>
            </div>
            <div class="post-nav-item">
                <a href="../202301050935/" rel="next" title="Kubernetes 上部署 cert-manager 及使用">
                  Kubernetes 上部署 cert-manager 及使用 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">COSMOS</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="300" alpha="0.3" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="../js/comments.js"></script><script src="../js/utils.js"></script><script src="../js/motion.js"></script><script src="../js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="../js/third-party/search/local-search.js"></script>




  <script src="../js/third-party/pace.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"fl9999","repo":"fl9999.github.io","client_id":"a11bf6f7860762b725b5","client_secret":"a99046105f8bddc72ec718d54dc3fd7f22070821","admin_user":"fl9999","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":null,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"d41d8cd98f00b204e9800998ecf8427e"}</script>
<script src="../js/third-party/comments/gitalk.js"></script>

</body>
</html>
